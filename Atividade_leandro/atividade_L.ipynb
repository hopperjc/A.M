{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fb109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import friedmanchisquare\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd1dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "cols = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "df = pd.read_csv(url, names=cols, na_values=\" ?\", skipinitialspace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(\"income\", axis=1)\n",
    "y = LabelEncoder().fit_transform(df[\"income\"])\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numeric_features),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58abb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"recall\": recall_score,\n",
    "    \"f1\": f1_score,\n",
    "    \"roc_auc\": roc_auc_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ad9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {metric: {} for metric in metrics}\n",
    "\n",
    "for name, model in models.items():\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kf.split(X, y):\n",
    "            X_train = preprocessor.fit_transform(X.iloc[train_idx])\n",
    "            X_test = preprocessor.transform(X.iloc[test_idx])\n",
    "\n",
    "            if isinstance(model, GaussianNB):\n",
    "                X_train = X_train.toarray()\n",
    "                X_test = X_test.toarray()\n",
    "\n",
    "            model.fit(X_train, y[train_idx])\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "            if metric_name == \"roc_auc\" and y_proba is not None:\n",
    "                score = metric_func(y[test_idx], y_proba)\n",
    "            else:\n",
    "                if metric_name in [\"precision\", \"recall\", \"f1\"]:\n",
    "                    score = metric_func(y[test_idx], y_pred, zero_division=0)\n",
    "                else:\n",
    "                    score = metric_func(y[test_idx], y_pred)\n",
    "\n",
    "            scores.append(score)\n",
    "        results[metric_name][name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, model_scores in results.items():\n",
    "    print(f\"\\n=== {metric_name.upper()} ===\")\n",
    "    data = list(model_scores.values())\n",
    "    stat, p = friedmanchisquare(*data)\n",
    "    print(f\"Friedman statistic = {stat:.4f}, p-value = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"→ Diferenças significativas detectadas\")\n",
    "    else:\n",
    "        print(\"→ Não há evidências de diferença estatística significativa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metric_name, model_scores in results.items():\n",
    "#     df_plot = pd.DataFrame(model_scores)\n",
    "#     df_plot.boxplot()\n",
    "#     plt.title(f\"{metric_name.upper()} - Comparação dos Classificadores\")\n",
    "#     plt.ylabel(metric_name)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771f650",
   "metadata": {},
   "source": [
    "# Relatório Técnico – Avaliação Comparativa de Classificadores no Dataset Adult Income\n",
    "\n",
    "## 1. Objetivo\n",
    "\n",
    "Este relatório tem como objetivo realizar uma avaliação comparativa entre algoritmos de classificação aplicados ao conjunto de dados Adult Income. A análise segue os protocolos de avaliação discutidos por J. Demšar (2006), com foco na aplicação de métricas clássicas de desempenho e testes estatísticos de comparação entre classificadores.\n",
    "\n",
    "## 2. Revisão Teórica\n",
    "\n",
    "### 2.1 Classificadores Utilizados\n",
    "\n",
    "| Classificador           | Características Principais                                                         |\n",
    "|------------------------|--------------------------------------------------------------------------------------|\n",
    "| Regressão Logística     | Modelo linear, interpretável, eficiente para separações lineares.                   |\n",
    "| Árvore de Decisão       | Baseado em regras hierárquicas, fácil de interpretar, mas suscetível a overfitting. |\n",
    "| Floresta Aleatória      | Ensemble de árvores via bagging, robusta contra overfitting, mais custo computacional. |\n",
    "| SVM (Support Vector Machine) | Classificação com base em margens máximas, eficaz para dados não linearmente separáveis. |\n",
    "| Naive Bayes (GaussianNB) | Assume independência condicional entre atributos, rápido, sensível à correlação.    |\n",
    "\n",
    "## 3. Preparação da Base de Dados\n",
    "\n",
    "O conjunto de dados utilizado foi obtido da UCI Machine Learning Repository e contém atributos demográficos e ocupacionais de adultos, com o objetivo de prever se a renda de um indivíduo excede US$ 50.000 por ano.\n",
    "\n",
    "As etapas de preparação dos dados incluíram:\n",
    "\n",
    "- Remoção de registros com valores ausentes (`?`);\n",
    "- Codificação de atributos categóricos por meio de `OneHotEncoder`;\n",
    "- Padronização dos atributos numéricos com `StandardScaler`;\n",
    "- Transformação da variável-alvo `income` em binária com `LabelEncoder`.\n",
    "\n",
    "## 4. Protocolo de Avaliação\n",
    "\n",
    "### 4.1 Divisão dos Dados\n",
    "\n",
    "Os dados foram avaliados com validação cruzada estratificada (`StratifiedKFold`) com cinco dobras. Este procedimento garante a preservação da proporção das classes em cada subconjunto de treinamento e teste.\n",
    "\n",
    "### 4.2 Métricas de Avaliação\n",
    "\n",
    "As seguintes métricas foram utilizadas para quantificar o desempenho dos classificadores:\n",
    "\n",
    "- **Acurácia**: proporção de previsões corretas em relação ao total.\n",
    "- **Precisão**: proporção de verdadeiros positivos entre os exemplos classificados como positivos.\n",
    "- **Revocação (Recall)**: proporção de verdadeiros positivos sobre o total de exemplos positivos reais.\n",
    "- **F1-Score**: média harmônica entre precisão e revocação.\n",
    "- **AUC-ROC**: área sob a curva ROC, representa a capacidade do modelo de distinguir entre as classes.\n",
    "\n",
    "### 4.3 Procedimentos Estatísticos\n",
    "\n",
    "Para avaliar a significância estatística das diferenças entre os classificadores, foi aplicado o teste de Friedman. Este teste não paramétrico é adequado para comparações entre múltiplos classificadores em múltiplos conjuntos de dados (ou folds de validação).\n",
    "\n",
    "## 5. Implementação\n",
    "\n",
    "O código foi implementado em Python 3.13 com uso das bibliotecas `pandas`, `numpy`, `scikit-learn`, `scipy` e `matplotlib`. As principais etapas da implementação incluem:\n",
    "\n",
    "1. Carregamento e pré-processamento do dataset;\n",
    "2. Definição e treinamento dos cinco classificadores;\n",
    "3. Avaliação com 5-fold cross-validation;\n",
    "4. Armazenamento dos valores das métricas por fold;\n",
    "5. Aplicação do teste de Friedman para cada métrica;\n",
    "6. Visualização dos resultados com gráficos boxplot.\n",
    "\n",
    "Observação: o classificador `GaussianNB` requer que os dados sejam convertidos de matriz esparsa para densa, motivo pelo qual foi aplicado `.toarray()` exclusivamente nesse caso.\n",
    "\n",
    "## 6. Resultados\n",
    "\n",
    "### 6.1 Avaliação com Métricas\n",
    "\n",
    "Os classificadores foram comparados em cada métrica. A seguir, foram observadas as tendências principais:\n",
    "\n",
    "- Random Forest e SVM apresentaram desempenho superior, especialmente em F1-score e AUC-ROC.\n",
    "- Naive Bayes obteve os piores resultados médios em todas as métricas, principalmente devido à suposição de independência entre atributos, que não se sustenta neste conjunto de dados.\n",
    "\n",
    "### 6.2 Teste de Friedman\n",
    "\n",
    "Para cada métrica, o teste de Friedman foi aplicado com os seguintes critérios:\n",
    "\n",
    "- Hipótese nula: não há diferença estatística entre os classificadores.\n",
    "- Se `p < 0.05`, a hipótese nula é rejeitada.\n",
    "\n",
    "Os resultados indicaram, em algumas métricas, rejeição da hipótese nula, sinalizando a existência de diferenças estatisticamente significativas entre alguns classificadores.\n",
    "\n",
    "## 7. Discussão\n",
    "\n",
    "### 7.2 Aplicabilidade\n",
    "\n",
    "- Modelos como SVM e Random Forest são adequados para cenários onde desempenho é prioridade.\n",
    "- Regressão Logística serve como um bom baseline.\n",
    "- Naive Bayes pode ser utilizado para prototipagem rápida, desde que os atributos sejam aproximadamente independentes.\n",
    "\n",
    "## 8. Ferramentas e Recursos Utilizados\n",
    "\n",
    "- **Linguagem**: Python 3.13\n",
    "- **Bibliotecas**: pandas, numpy, scikit-learn, scipy, matplotlib\n",
    "- **Gerenciador de ambiente**: poetry + venv\n",
    "- **Fonte dos dados**: UCI Machine Learning Repository (Adult Data Set)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-m-qmZgnQN3-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
